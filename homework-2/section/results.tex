\section{Results and Discussion}
\label{sec:results}

Results suggest that French queries perform better than their English counterparts, possibly due to the training data's
French origin and later translation into English.
Moreover, the IR system's effectiveness generally increases with a larger N-gram size, as indicated by the higher scores
of \texttt{en\_en\_5gram} and \texttt{fr\_fr\_5gram}.
Conversely, the inclusion of NER in the indexing process seems to have a negative impact on the scores, as shown by the
lower scores of \texttt{en\_en\_4gram\_ner} and \texttt{fr\_fr\_4gram\_ner}.
The use of query expansion with synonyms in English does not seem to improve the search results to any great extent.\\

It's interesting to notice that the cross-language approaches (\texttt{en\_en\_fr\_5gram} and
\texttt{fr\_en\_fr\_5gram}) are out of the five bests systems.
It turns out that searching for English words in French documents and vice versa messes up the search, lowering the
score.
Another interesting aspect is that the worst-performing index is the one with named entity recognition in English
(\texttt{en\_en\_4gram\_ner}): it combines translated queries and NER, which appears to be the two worst-performing
approaches.\\

In general, we focus more on trying multiple approaches, this is why our score has such a big space for improvement.
As already said, French queries with bigger N-gram sizes perform better.
Instead of relying on single-word matches, the queries could take place with more context, resulting in better search
results.\\

\subsection{Short Term Test Data}

%TODO: Here we should include a table like the one we have previously done (MAP, nDCG, but also RnD) for the SHORT TERM runs, for the 5 systems submitted to CLEF.
%TODO: this is, we have to use trec_eval with the new qrels.txt file (for SHORT TERM) that have been submitted to CLEF on 22/5/2023 (see CLEF web page)

\subsection{Long Term Test Data}

%TODO: Here we should include a table like the one we have previously done (MAP, nDCG, but also RnD) for the LONG TERM runs, for the 5 systems submitted to CLEF.
%TODO: this is, we have to use trec_eval with the new qrels.txt file (for LONG TERM) that have been submitted to CLEF on 22/5/2023 (see CLEF web page)

\subsection{Anova 2 Analysis}

%TODO: here we have to do a 2 ways Anova for our five systems.