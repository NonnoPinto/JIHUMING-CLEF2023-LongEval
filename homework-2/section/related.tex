\section{Related Work}
\label{sec:related}

% About our techniques
There are many search engines, using different techniques to enhance retrieval effectiveness, from which we have taken
inspiration from.\\

The BM25~\cite{BM25} similarity function is widely used information retrieval as it considers term frequencies and document length.
This function has demonstrated effectiveness in balancing precision and recall in search results, even if it
doesn't consider meta-data document information as other approaches~\cite{robertson2009probabilistic} do.
Whitespace tokenization has not been the primary focus of research in any study.
Anyway, it seems to provide a useful baseline for tokenization;
Gow-Smith et al.~\cite{gowsmith2022improving} suggests that allowing tokens to include spaces causes problems,
especially in architectures including transformers.
Token lowercasing is also a recurring method in information retrieval~\cite{manning2008introduction}, mainly because it
reduces the vocabulary size;
it is always applied after more advanced token filters as \textit{WordDelimiterGraphFilter}.\\

The TERRIER stopword list has been used in plenty of search engines because of the good results if offers working with
web documents as blogs~\cite{Ounis2006OverviewOT} or even recommender systems.
Another basic information retrieval technique used in our search engine has been stemming.
We have relied on the work of Jivani et al.\cite{jivani2011comparative} to get an overview of the most adequate stemming
techniques for our documents.
For the English documents we have chosen a minimal stemmer developed by K. Harman~\cite{Harman1991HowEI}.
For the French documents we have also used a minimal stemmer developed by J. Savoy~\cite{frenchStemmer}.
\\

We have used query expansion~\cite{efthimiadis1996query} in order to broaden the search scope by including additional
synonyms related to the original query.
These synonyms come from WordNet~\cite{Fellbaum1998}, a popular lexical database that provides semantic relationships
between words.

% About our approach
In the paper "Learning to Estimate Query Temporal Dynamics for Web Search" ~\cite{cai2014learning}, the importance of
understanding query temporal dynamics for search result ranking is highlighted.
By considering the temporal patterns of queries, search engines can adapt their ranking algorithms to better meet the
evolving information needs of users.
This can involve giving more weight to recent queries or adjusting the ranking based on the popularity of certain topics
during specific time periods.
By incorporating query temporal dynamics into the ranking process, search engines can deliver more relevant and timely
search results.\\

In the context of our task of assessing an information retrieval system with changing datasets, learning and estimating
query temporal dynamics can be highly relevant.
By leveraging the methods and techniques discussed in the paper, it can enhance our information retrieval system's
performance in addressing evolving user information needs.
Understanding the temporal patterns of queries can guide the system's adaptation to changes in the datasets, enabling it
to provide more accurate and timely search results. \\

The paper "Evaluating Web Search Systems Considering Time" ~\cite{hofmann2014evaluating} presents valuable insights into
evaluation methodologies for temporal aspects in web search systems.
While the paper focuses specifically on web search, many of the concepts and methodologies discussed can be applied to
the task of assessing an information retrieval system with changing datasets. \\

Specifically, the paper explores metrics for evaluating retrieval effectiveness over time.
These metrics can be utilized to measure the performance of your information retrieval system in handling the changing
datasets.
Consider incorporating relevant metrics, such as precision, recall, F1-score, and mean average precision (MAP), as
discussed in the paper, to evaluate the system's effectiveness in retrieving relevant information across different time
periods.\\

For experimental setups, the paper provides insights into various setups, including time-sliced evaluation, incremental
evaluation, and evaluation with simulated temporal queries.
These setups can serve as a basis for designing your own experimental setups that align with your specific task
requirements.\\

By leveraging the insights from the paper, we can incorporate evaluation methodologies, metrics, and experimental setups
specifically tailored for temporal information retrieval.
This comprehensive approach will enable you to assess the performance of your information retrieval system in handling
changes over time, evaluating its adaptability to evolving datasets and user queries.\\
