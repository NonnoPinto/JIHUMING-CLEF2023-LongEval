\section{Methodology}
\label{sec:methodology}
In this section we address how the system was developed starting from the source code of
HelloTipster\cite{tipser} repository developed by Professor Nicola Ferro
and presented to us during the Search Engine course.
Furthermore, we will present main methodology and approaches
using the same structure of the repository\cite{jihuming}.

\subsection{Parsing}
We had a huge collection of documents in English and French. First thing
was to manually examine document to understand how to read them. As described
\href{https://github.com/joaopalotti/trectools}{in his GitHub repository},
documents use a particular format, which includes a DOCNO and a DOCID.
The DOCNO is the id of the document and the DOCID is the id of the collection.\\
JSON, on the other side, follows the mouch more standard
\href{https://github.com/castorini/anserini/issues/1111}{following structure}.\\
The whole parser is made by:
\begin{itemize}
    \item \texttt{DocumentParser}: parses trec document
    \item \texttt{JsonDocument}: create a class for json doc
    \item \texttt{LongEvalParser}: counts the document and print out
    \item \texttt{ParsedDocument}: document parsed has FIELDS including ID,
    ENGLISH\textunderscore BODY, and FRENCH\textunderscore BODY
\end{itemize}
\subsection{Analyzer}
As basis for the analyzer we used the TokenStream class from Lucene, which 
Consumes a TokenStream for the given text by using the provided
Analyzer and prints diagnostic information about all the generated tokens and
their Attributes.\\
Streams are analyzed by applying these filters:
\begin{itemize}
    \item \texttt{WhitespaceTokenizer}: splits on and discards only
    whitespace characters %TODO: initizlized but never used
    \item \texttt{PatternReplaceFilter}: it's applied twice. First time, using RegExpr patter deletes punctuations
    marks at the beginning of tokens, second time it does the same but at the end of them
    \item \texttt{WordDelimiterGraphFilter}: it splits words into subwords and performs optional transformations on subword groups.
        In our case, we decided to use these filters:
    \begin{lstlisting}[language=Java]
WordDelimiterGraphFilter.GENERATE_WORD_PARTS
                    // Ex: "PowerShot" => "Power" "Shot"
| WordDelimiterGraphFilter.GENERATE_NUMBER_PARTS
                    // Ex: "500-42" => "500" "42"
| WordDelimiterGraphFilter.CATENATE_NUMBERS
                    // Ex: "500-42" => "50042"
| WordDelimiterGraphFilter.PRESERVE_ORIGINAL
                    // Ex: "500-42" => "500" "42" "500-42"
| WordDelimiterGraphFilter.SPLIT_ON_CASE_CHANGE
                    // Causes lowercase -> uppercase transition to start a new subword.
| WordDelimiterGraphFilter.STEM_ENGLISH_POSSESSIVE
                    // "O'Neil's" => "O", "Neil"
    \end{lstlisting}
    \item \texttt{LowerCaseFilter}: converts all characters to lowercase %TODO: are we checking for BRAND names? (apple == Apple?)
    \item \texttt{StopFilter}: removes stop words applying terrier list\cite{stopword}
    \item \texttt{SynonymTokenFilter}: only for English analyzer, it uses WordNet lexical database\cite{wordnet} to group words
        interlinked by means of conceptual-semantic and lexical relations
    \item \texttt{MinimalStemFilter}: implementing S-Stemmer from Harman article\cite{engStemFilter} for English language
        and Savoy stemming procedure\cite{frStemFilter}, it divides words into stems
    \item \texttt{EmptyTokenFilter}: removes tokens with length 0
\end{itemize}
    Lastly, the \texttt{NGramAnalyzer} is applied, trying tokens of one, two and three words. We decided to set the max at three,
    but this number is heuristic and can be changed if results shows better numbers.\\

\subsection{Index}
We used the standard Lucene Indexer with the BM25\cite{BM25} similarity.\\
%TODO: explain the deprecated indexers
We decide to use NGram analyzer with a multilingual indexer,
in order to index two version of the same document, creating documents with
an unique ID and bodies from each language.\\
Ngrams are represented as characters from both English and French version of
the documents. N parameter is set at the analyzer level and class is a field,
not stored, in order to minimize space occupation.\\
%TODO: still lot to write

\subsection{Search}

\subsection{Topic}